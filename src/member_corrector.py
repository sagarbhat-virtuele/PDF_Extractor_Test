"""
OCR Pattern Corrector for Steel Members
Fixes common OCR errors BEFORE validation
"""

import re
import json
from typing import Dict, List, Tuple
from collections import defaultdict
from pathlib import Path
from datetime import datetime


class OCRCorrector:
    """Correct common OCR errors in steel member designations"""
    
    def __init__(self):
        # Character substitution rules (OCR mistakes)
        self.char_substitutions = {
            'I': '1',   # I â†’ 1 (most common)
            'O': '0',   # O â†’ 0
            'l': '1',   # lowercase L â†’ 1
            'S': '5',   # S â†’ 5 (in numbers)
            'B': '8',   # B â†’ 8 (in numbers)
            'Z': '2',   # Z â†’ 2
            'G': '6',   # G â†’ 6
            'â€”': 'X',   # em dash â†’ X
            'â€“': 'X',   # en dash â†’ X
            'x': 'X',   # lowercase â†’ uppercase
            '%': '',    # noise character
            "'": '',    # apostrophe noise
            '"': '',    # quote noise
            ',': '.',   # comma â†’ decimal
        }
        
        # Pattern-based corrections
        self.pattern_rules = [
            # Rule 1: Fix W-sections with I instead of 1
            (r'W([I|l])(\d+)', r'W1\2'),  # WI0X17 â†’ W10X17
            
            # Rule 2: Fix W-sections with O instead of 0
            (r'W([O])(\d+)', r'W0\2'),    # WO8X10 â†’ W08X10
            
            # Rule 3: Fix channel designation with missing decimal
            (r'C(\d+)X(\d)(\d)(\d)', r'C\1X\2.\3'),  # C8X115 â†’ C8X11.5
            
            # Rule 4: Fix HSS with dashes or noise
            (r'HSS(\d+)[xâ€”â€“](\d+)[xâ€”â€“](.+)', r'HSS\1X\2X\3'),
            
            # Rule 5: Remove duplicate text (W2.0xW2.0 â†’ W20X...)
            (r'W(\d)\.(\d)XW(\d)\.(\d)', r'W\1\2X\3\4'),
            
            # Rule 6: Fix missing C prefix for channels
            (r'^(\d+)X(\d+\.?\d*)', r'C\1X\2'),  # 12X20.7 â†’ C12X20.7
            
            # Rule 7: Fix angle with noise
            (r'L(\d+)[x](\d+)[x](.+)', r'L\1X\2X\3'),
            
            # Rule 8: Fix sections with comma instead of decimal
            (r'X(\d+),(\d+)', r'X\1.\2'),  # X11,5 â†’ X11.5
            
            # Rule 9: Remove noise characters
            (r'[%\'"]', r''),
            
            # Rule 10: Fix sections ending with noise
            (r'([A-Z]\d+X\d+)â€”+', r'\1'),
        ]
        
        # Context-aware corrections (based on typical steel sections)
        self.contextual_rules = {
            # Typical W-sections
            'W_sections': {
                'W1': ['W10', 'W12', 'W14', 'W16', 'W18', 'W21'],
                'W2': ['W20', 'W21', 'W24', 'W27'],
                'W3': ['W30', 'W33', 'W36'],
            },
            # Typical C-sections
            'C_sections': {
                'C': ['C3', 'C4', 'C5', 'C6', 'C8', 'C10', 'C12', 'C15'],
            },
            # Typical HSS
            'HSS_sections': {
                'HSS': ['HSS4X4', 'HSS5X5', 'HSS6X6', 'HSS8X8', 'HSS10X10'],
            }
        }
        
        # Statistics
        self.correction_stats = defaultdict(int)
        self.corrections_made = []
    
    def correct_member_id(self, member_id: str, context: Dict = None) -> Tuple[str, bool, str]:
        """
        Correct a single member ID
        
        Args:
            member_id: Original member ID
            context: Optional context (nearby text, page info, etc.)
        
        Returns:
            (corrected_id, was_corrected, correction_type)
        """
        original = member_id
        corrected = member_id.upper().strip()
        correction_type = 'NONE'
        
        # Step 1: Character substitutions in numeric parts
        corrected = self._apply_char_substitutions(corrected)
        
        # Step 2: Pattern-based corrections
        corrected, pattern_applied = self._apply_pattern_rules(corrected)
        if pattern_applied:
            correction_type = 'PATTERN'
        
        # Step 3: Context-aware corrections
        corrected = self._apply_contextual_rules(corrected)
        
        # Step 4: Cleanup
        corrected = self._cleanup(corrected)
        
        was_corrected = (original != corrected)
        
        if was_corrected:
            self.correction_stats[correction_type] += 1
            self.corrections_made.append({
                'original': original,
                'corrected': corrected,
                'type': correction_type
            })
        
        return corrected, was_corrected, correction_type
    
    def _apply_char_substitutions(self, text: str) -> str:
        """Apply character-level substitutions intelligently"""
        # Only substitute in numeric context
        result = []
        
        for i, char in enumerate(text):
            # Look at surrounding context
            prev_char = text[i-1] if i > 0 else ''
            next_char = text[i+1] if i < len(text)-1 else ''
            
            # If we're in a numeric context, apply substitutions
            if char in self.char_substitutions:
                # Check if we should substitute
                if self._is_numeric_context(prev_char, next_char):
                    result.append(self.char_substitutions[char])
                else:
                    result.append(char)
            else:
                result.append(char)
        
        return ''.join(result)
    
    def _is_numeric_context(self, prev_char: str, next_char: str) -> bool:
        """Check if we're in a numeric context"""
        # After a letter followed by possible number (W|10 or C|8)
        if prev_char.isalpha():
            return True
        # Between numbers (1|0 or 1|5)
        if prev_char.isdigit() or next_char.isdigit():
            return True
        # After X (W12X|10)
        if prev_char == 'X':
            return True
        return False
    
    def _apply_pattern_rules(self, text: str) -> Tuple[str, bool]:
        """Apply regex pattern rules"""
        applied = False
        result = text
        
        for pattern, replacement in self.pattern_rules:
            new_result = re.sub(pattern, replacement, result)
            if new_result != result:
                result = new_result
                applied = True
        
        return result, applied
    
    def _apply_contextual_rules(self, text: str) -> str:
        """Apply context-aware corrections"""
        # Check if it looks like a common section with errors
        
        # W-sections
        if text.startswith('W') and len(text) >= 3:
            # Extract depth (first digits)
            match = re.match(r'W(\d+)', text)
            if match:
                depth = match.group(1)
                # If depth is 1-digit and likely should be 2-digit
                if len(depth) == 1 and depth in '123':
                    # Common depths: W10, W12, W14, W16, W18, W21, W24, W27, W30, W33, W36
                    # This heuristic helps
                    pass
        
        return text
    
    def _cleanup(self, text: str) -> str:
        """Final cleanup"""
        # Remove duplicate characters that don't make sense
        text = re.sub(r'([A-Z])\1{2,}', r'\1', text)  # XXX â†’ X
        
        # Standardize spacing
        text = text.replace(' ', '')
        
        # Remove trailing noise
        text = re.sub(r'[^A-Z0-9.X]+$', '', text)
        
        return text
    
    def correct_semantic_results(self, semantic_json_path: str, output_path: str = None) -> Dict:
        """
        Correct all members in semantic analysis results
        
        Args:
            semantic_json_path: Path to member_summary_*.json
            output_path: Where to save corrected results (optional)
        
        Returns:
            Corrected semantic data
        """
        print(f"{'='*80}")
        print("OCR CORRECTION - STEEL MEMBERS")
        print(f"{'='*80}\n")
        
        print(f"Loading: {semantic_json_path}")
        with open(semantic_json_path, 'r') as f:
            data = json.load(f)
        
        members = data.get('members', [])
        print(f"Found {len(members)} members to check\n")
        
        print(f"{'â”€'*80}")
        print("CORRECTIONS")
        print(f"{'â”€'*80}")
        
        corrected_members = []
        
        for member in members:
            original_id = member['id']
            
            # Correct the main ID
            corrected_id, was_corrected, correction_type = self.correct_member_id(original_id)
            
            # Correct variants
            corrected_variants = []
            for variant in member.get('variants', []):
                corr_var, _, _ = self.correct_member_id(variant)
                corrected_variants.append(corr_var)
            
            # Update member data
            corrected_member = member.copy()
            corrected_member['id'] = corrected_id
            corrected_member['original_id'] = original_id
            corrected_member['was_corrected'] = was_corrected
            corrected_member['correction_type'] = correction_type
            corrected_member['variants'] = list(set(corrected_variants))  # Deduplicate
            
            corrected_members.append(corrected_member)
            
            # Log correction
            if was_corrected:
                print(f"  âœ“ {original_id:20s} â†’ {corrected_id}")
        
        # Update data
        data['members'] = corrected_members
        
        # Add correction metadata
        data['correction_metadata'] = {
            'corrected_at': datetime.now().isoformat(),
            'original_file': semantic_json_path,
            'total_members': len(members),
            'corrections_made': len([m for m in corrected_members if m['was_corrected']]),
            'correction_stats': dict(self.correction_stats)
        }
        
        # Print statistics
        print(f"\n{'â”€'*80}")
        print("CORRECTION STATISTICS")
        print(f"{'â”€'*80}")
        print(f"Total members:       {len(members)}")
        print(f"Corrected:           {len([m for m in corrected_members if m['was_corrected']])}")
        print(f"Unchanged:           {len([m for m in corrected_members if not m['was_corrected']])}")
        
        if self.correction_stats:
            print(f"\nBy type:")
            for corr_type, count in self.correction_stats.items():
                print(f"  {corr_type}: {count}")
        
        # Save corrected results
        if output_path is None:
            # Auto-generate output path
            original_path = Path(semantic_json_path)
            output_path = original_path.parent / f"{original_path.stem}_CORRECTED{original_path.suffix}"
        
        with open(output_path, 'w') as f:
            json.dump(data, f, indent=2)
        
        print(f"\nâœ“ Corrected results saved: {output_path}")
        
        return data
    
    def generate_correction_report(self, output_path: str):
        """Generate detailed correction report"""
        with open(output_path, 'w') as f:
            f.write("="*80 + "\n")
            f.write("OCR CORRECTION REPORT\n")
            f.write("="*80 + "\n\n")
            
            f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("-"*80 + "\n")
            f.write("CORRECTIONS MADE\n")
            f.write("-"*80 + "\n\n")
            
            if self.corrections_made:
                for corr in self.corrections_made:
                    f.write(f"{corr['original']:20s} â†’ {corr['corrected']:20s} [{corr['type']}]\n")
            else:
                f.write("No corrections needed.\n")
            
            f.write("\n" + "-"*80 + "\n")
            f.write("STATISTICS\n")
            f.write("-"*80 + "\n")
            f.write(f"Total corrections: {len(self.corrections_made)}\n")
            for corr_type, count in self.correction_stats.items():
                f.write(f"  {corr_type}: {count}\n")
            
            f.write("\n" + "="*80 + "\n")
        
        print(f"âœ“ Correction report saved: {output_path}")


class OCRAwareValidator:
    """Validator that uses OCR-corrected results"""
    
    def __init__(self, excel_path: str, corrected_semantic_path: str):
        self.excel_path = excel_path
        self.corrected_semantic_path = corrected_semantic_path
    
    def validate_with_corrections(self):
        """Run validation with OCR-corrected data"""
        # Import the validator from previous artifact
        from member_validator_marker import MemberValidator
        
        print(f"\n{'='*80}")
        print("VALIDATION WITH OCR-CORRECTED DATA")
        print(f"{'='*80}\n")
        
        validator = MemberValidator(self.excel_path, self.corrected_semantic_path)
        validation_results = validator.validate()
        
        return validation_results


# ============================================================================
# COMPLETE WORKFLOW: CORRECT â†’ VALIDATE â†’ MARK
# ============================================================================

def complete_workflow(
    semantic_json: str,
    excel_path: str,
    pdf_path: str,
    output_dir: str = 'corrected_validation'
):
    """
    Complete workflow: OCR Correction â†’ Validation â†’ PDF Marking
    
    Args:
        semantic_json: Original member_summary_*.json from semantic analysis
        excel_path: Excel file with reference members
        pdf_path: Original PDF to mark
        output_dir: Output directory
    """
    
    Path(output_dir).mkdir(exist_ok=True)
    
    print(f"{'='*80}")
    print("COMPLETE WORKFLOW: CORRECT â†’ VALIDATE â†’ MARK")
    print(f"{'='*80}\n")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ===== STEP 1: OCR CORRECTION =====
    print("\n" + "â–¶"*40)
    print("STEP 1: OCR CORRECTION")
    print("â–¶"*40)
    
    corrector = OCRCorrector()
    corrected_path = Path(output_dir) / f"member_summary_CORRECTED_{timestamp}.json"
    corrected_data = corrector.correct_semantic_results(semantic_json, str(corrected_path))
    
    # Save correction report
    corr_report_path = Path(output_dir) / f"correction_report_{timestamp}.txt"
    corrector.generate_correction_report(str(corr_report_path))
    
    # ===== STEP 2: VALIDATION =====
    print("\n" + "â–¶"*40)
    print("STEP 2: VALIDATION")
    print("â–¶"*40)
    
    from member_validator_marker import MemberValidator, save_readable_report
    
    validator = MemberValidator(excel_path, str(corrected_path))
    validation_results = validator.validate()
    
    # Save validation reports
    val_json_path = Path(output_dir) / f"validation_report_{timestamp}.json"
    validator.save_validation_report(str(val_json_path))
    
    val_txt_path = Path(output_dir) / f"validation_report_{timestamp}.txt"
    save_readable_report(validation_results, str(val_txt_path))
    
    # ===== STEP 3: PDF MARKING =====
    print("\n" + "â–¶"*40)
    print("STEP 3: PDF MARKING")
    print("â–¶"*40)
    
    from member_validator_marker import PDFMarker
    
    marker = PDFMarker(pdf_path, validation_results)
    marker.create_marked_versions(output_dir)
    
    # ===== FINAL SUMMARY =====
    print(f"\n{'='*80}")
    print("âœ… COMPLETE WORKFLOW FINISHED!")
    print(f"{'='*80}\n")
    
    print("ğŸ“Š SUMMARY:")
    print(f"  OCR Corrections:    {len([m for m in corrected_data['members'] if m['was_corrected']])}")
    print(f"  Matched Members:    {validation_results['statistics']['matched']}")
    print(f"  Match Rate:         {validation_results['statistics']['match_rate']:.1f}%")
    print(f"  Unmatched:          {validation_results['statistics']['unmatched_detected']}")
    print(f"  Missing from PDF:   {validation_results['statistics']['missing_from_pdf']}")
    
    print(f"\nğŸ“ OUTPUT:")
    print(f"  {output_dir}/")
    print(f"  â”œâ”€â”€ member_summary_CORRECTED_*.json      # OCR-corrected members")
    print(f"  â”œâ”€â”€ correction_report_*.txt              # OCR corrections log")
    print(f"  â”œâ”€â”€ validation_report_*.json/.txt        # Validation results")
    print(f"  â”œâ”€â”€ marked_MATCHED_*.pdf                 # Matched members (GREEN)")
    print(f"  â”œâ”€â”€ marked_UNMATCHED_*.pdf               # Unmatched members (RED)")
    print(f"  â””â”€â”€ marked_ALL_*.pdf                     # All members (color-coded)")
    
    print(f"\nâœ¨ All outputs in: {Path(output_dir).absolute()}")
    
    return {
        'corrected_data': corrected_data,
        'validation_results': validation_results,
        'output_dir': output_dir
    }


# ============================================================================
# COMMAND-LINE INTERFACE
# ============================================================================

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) >= 4:
        semantic_json = sys.argv[1]
        excel_path = sys.argv[2]
        pdf_path = sys.argv[3]
        
        complete_workflow(
            semantic_json=semantic_json,
            excel_path=excel_path,
            pdf_path=pdf_path,
            output_dir='corrected_validation'
        )
    else:
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               OCR CORRECTION â†’ VALIDATION â†’ MARKING                        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

USAGE:
    python ocr_corrector.py <semantic_json> <excel_file> <pdf_file>

EXAMPLE:
    python ocr_corrector.py \\
        output/reports/member_summary_20240115.json \\
        member_list.xlsx \\
        A1.pdf

WHAT IT DOES:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ STEP 1: OCR CORRECTION                                      â”‚
    â”‚  â€¢ Fixes common OCR errors:                                 â”‚
    â”‚    - I â†’ 1  (WIOXT7 â†’ W10X17)                              â”‚
    â”‚    - O â†’ 0  (WO8X10 â†’ W08X10)                              â”‚
    â”‚    - Missing decimals (C8X115 â†’ C8X11.5)                   â”‚
    â”‚    - Duplicate text (W2.0xW2.0 â†’ W20X20)                   â”‚
    â”‚    - Missing prefix (12X207 â†’ C12X20.7)                    â”‚
    â”‚    - Noise characters (HSS6x6â€”% â†’ HSS6X6)                  â”‚
    â”‚  â€¢ Creates corrected member list                            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ STEP 2: VALIDATION                                          â”‚
    â”‚  â€¢ Compares corrected members with Excel                    â”‚
    â”‚  â€¢ Identifies: matched, unmatched, missing                  â”‚
    â”‚  â€¢ Calculates match rate                                    â”‚
    â”‚  â€¢ Generates validation reports                             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ STEP 3: PDF MARKING                                         â”‚
    â”‚  â€¢ Highlights members on PDF:                               â”‚
    â”‚    ğŸŸ¢ GREEN  = Matched with Excel                           â”‚
    â”‚    ğŸ”´ RED    = Unmatched (needs review)                     â”‚
    â”‚  â€¢ Creates 3 marked PDF versions                            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

OUTPUTS:
    corrected_validation/
    â”œâ”€â”€ member_summary_CORRECTED_*.json      # âœ¨ OCR-corrected data
    â”œâ”€â”€ correction_report_*.txt              # What was fixed
    â”œâ”€â”€ validation_report_*.json/.txt        # Validation results
    â”œâ”€â”€ marked_MATCHED_*.pdf                 # Green highlights
    â”œâ”€â”€ marked_UNMATCHED_*.pdf               # Red highlights
    â””â”€â”€ marked_ALL_*.pdf                     # Color-coded

COMMON OCR FIXES:
    C8X115       â†’ C8X11.5      (missing decimal)
    WIOXT7       â†’ W10X17       (I â†’ 1)
    WI0X12       â†’ W10X12       (I â†’ 1)
    W20XW20      â†’ W20X20       (duplicate removal)
    12X207       â†’ C12X20.7     (missing C prefix)
    HSS6x6â€”%     â†’ HSS6X6       (noise removal)
    C10x15       â†’ C10X15.3     (missing decimal)
    
EXPECTED IMPROVEMENT:
    Before OCR correction:  ~50-60% match rate
    After OCR correction:   ~85-95% match rate
        """)